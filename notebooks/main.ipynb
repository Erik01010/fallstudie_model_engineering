{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64331896-8016-4287-bcfa-f5d2eb42f8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.stats import uniform, randint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    RandomizedSearchCV,\n",
    "    GridSearchCV,\n",
    "    StratifiedKFold,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    precision_recall_curve,\n",
    "    PrecisionRecallDisplay,\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "RAW_DATA_PATH = \"../data/data.xlsx\"\n",
    "\n",
    "CAT_FEATURES = [\n",
    "    \"PSP\",\n",
    "    \"country\",\n",
    "    \"card\",\n",
    "    \"amount_bins\",\n",
    "    \"interaction_psp_country\",\n",
    "    \"interaction_psp_card\",\n",
    "    \"interaction_psp_amount_bin\",\n",
    "    \"interaction_psp_3D_secured\",\n",
    "]\n",
    "\n",
    "CYCLICAL_FEATURES = {\"day\": 31, \"dow\": 7, \"hour\": 24}\n",
    "\n",
    "PSP_COSTS = {\n",
    "    \"Moneycard\": {\"success\": 5, \"failure\": 2},\n",
    "    \"Goldcard\": {\"success\": 10, \"failure\": 5},\n",
    "    \"UK_Card\": {\"success\": 3, \"failure\": 1},\n",
    "    \"Simplecard\": {\"success\": 1, \"failure\": 0.5},\n",
    "}\n",
    "\n",
    "PARAM_DIST = {\n",
    "    \"learning_rate\": uniform(0.01, 0.2),\n",
    "    \"max_iter\": randint(100, 500),\n",
    "    \"max_depth\": randint(3, 15),\n",
    "    \"l2_regularization\": uniform(0, 1),\n",
    "    \"min_samples_leaf\": randint(20, 100),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "078fef9b-ddcb-4928-8fff-9afdf26f0252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(data: pd.DataFrame) -> tuple[pd.DataFrame, OneHotEncoder]:\n",
    "    \"\"\"Drop duplicates and generate Features.\"\"\"\n",
    "    data = data.copy()\n",
    "    data = data.drop_duplicates()\n",
    "\n",
    "    # Informationen aus Zeitstempel extrahieren\n",
    "    data[\"month\"] = data.loc[:, \"tmsp\"].dt.month.astype(\"int64\")\n",
    "    data[\"week\"] = data.loc[:, \"tmsp\"].dt.isocalendar().week.astype(\"int64\")\n",
    "    data[\"day\"] = data.loc[:, \"tmsp\"].dt.day.astype(\"int64\")\n",
    "    data[\"dow\"] = data.loc[:, \"tmsp\"].dt.dayofweek.astype(\"int64\")\n",
    "    data[\"hour\"] = data.loc[:, \"tmsp\"].dt.hour.astype(\"int64\")\n",
    "    data[\"second\"] = data.loc[:, \"tmsp\"].dt.second.astype(\"int64\")\n",
    "    data[\"is_weekend\"] = data[\"dow\"] >= 5\n",
    "    data[\"is_business_hours\"] = (data[\"hour\"] >= 8) & (data[\"hour\"] < 20)\n",
    "\n",
    "    # Zeit-Features zyklisch kodieren\n",
    "    # week und month nicht zyklisch kodieren da kein ZyklusÃ¼bergang\n",
    "    for key, value in CYCLICAL_FEATURES.items():\n",
    "        data[f\"{key}_sin\"] = np.sin(2 * np.pi * data[key] / value)\n",
    "        data[f\"{key}_cos\"] = np.cos(2 * np.pi * data[key] / value)\n",
    "\n",
    "    # Kosten\n",
    "    data[\"cost_if_success\"] = data[\"PSP\"].map(lambda psp: PSP_COSTS[psp][\"success\"])\n",
    "    data[\"cost_if_failure\"] = data[\"PSP\"].map(lambda psp: PSP_COSTS[psp][\"failure\"])\n",
    "\n",
    "    # Wiederholte Transaktionsversuche aufgrund fehlgeschlagener Transaktionen\n",
    "    data[\"timedelta\"] = data[\"tmsp\"].diff().dt.total_seconds().fillna(0).astype(\"int64\")\n",
    "    cols_to_compare = [\"country\", \"amount\", \"3D_secured\", \"card\"]\n",
    "    data[\"is_retry\"] = (data[cols_to_compare] == data[cols_to_compare].shift(1)).all(axis=1)\n",
    "    data[\"is_retry\"] = data[\"is_retry\"] & (data[\"timedelta\"] <= 60)\n",
    "\n",
    "    # Anzahl kontinuierlicher Retry Versuche\n",
    "    retry_groups = (~data[\"is_retry\"]).cumsum()\n",
    "    data[\"retry_count\"] = data.groupby(retry_groups)[\"is_retry\"].cumsum().astype(\"int64\")\n",
    "\n",
    "    # Wechsel PSP bei Retry\n",
    "    data[\"PSP_switch\"] = data.groupby(retry_groups)[\"PSP\"].transform(\n",
    "        lambda x: (x != x.shift()).fillna(False).cumsum() > 0\n",
    "    )\n",
    "\n",
    "    data[\"amount_bins\"] = pd.cut(\n",
    "        data[\"amount\"],\n",
    "        bins=[0, 200, 400, float(\"inf\")],\n",
    "        labels=[\"amount_under_200\", \"amount_200_400\", \"amount_over_400\"],\n",
    "        right=False,\n",
    "    )\n",
    "\n",
    "    # Feature interaktion: PSP und Country\n",
    "    data[\"interaction_psp_country\"] = data[\"PSP\"] + \"_\" + data[\"country\"]\n",
    "    data[\"interaction_psp_card\"] = data[\"PSP\"] + \"_\" + data[\"card\"]\n",
    "    data[\"interaction_psp_amount_bin\"] = data[\"PSP\"] + \"_\" + data[\"amount_bins\"].astype(str)\n",
    "    data[\"interaction_psp_3D_secured\"] = data[\"PSP\"] + \"_\" + data[\"3D_secured\"].astype(str)\n",
    "\n",
    "    # kategorische Merkmale encodieren\n",
    "    ohc = train_ohc_encoder(data=data[CAT_FEATURES])\n",
    "    encoded_array = ohc.transform(data[CAT_FEATURES])\n",
    "    encoded_columns = ohc.get_feature_names_out(CAT_FEATURES)\n",
    "    encoded_df = pd.DataFrame(encoded_array, columns=encoded_columns, index=data.index)\n",
    "    data = pd.concat([data, encoded_df], axis=1)\n",
    "\n",
    "    # Timestamp und nicht kategorische features entfernen\n",
    "    cat_features = CAT_FEATURES + [\"tmsp\"]\n",
    "    data = data.drop(columns=cat_features, axis=1)\n",
    "\n",
    "    return (data, ohc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1899489d-c37e-4206-a029-5b5f17865882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ohc_encoder(data: pd.DataFrame) -> OneHotEncoder:\n",
    "    \"\"\"Trains and saves a OneHotEncoder for categorical features.\"\"\"\n",
    "    one_hot_encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"warn\")\n",
    "    one_hot_encoder.fit(data)\n",
    "    return one_hot_encoder\n",
    "\n",
    "\n",
    "def train_decision_tree(\n",
    "    x_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    ") -> DecisionTreeClassifier:\n",
    "    \"\"\"Trains a Decision Tree Classifier.\"\"\"\n",
    "    decision_tree_model = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "    decision_tree_model.fit(x_train, y_train)\n",
    "\n",
    "    return decision_tree_model\n",
    "\n",
    "\n",
    "def train_hgboost(\n",
    "    x_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    ") -> HistGradientBoostingClassifier:\n",
    "    \"\"\"Trains a HGBoost Classifier.\"\"\"\n",
    "    hgboost_model = HistGradientBoostingClassifier(random_state=42, class_weight=\"balanced\")\n",
    "    hgboost_model.fit(x_train, y_train)\n",
    "\n",
    "    return hgboost_model\n",
    "\n",
    "\n",
    "def tune_hyperparameters(x_train: pd.DataFrame, y_train: pd.DataFrame) -> HistGradientBoostingClassifier:\n",
    "    \"\"\"Run randomized search to find the best hyperparameters.\"\"\"\n",
    "    hgboost_model = HistGradientBoostingClassifier(random_state=42, class_weight=\"balanced\")\n",
    "    cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=hgboost_model,\n",
    "        param_distributions=PARAM_DIST,\n",
    "        n_iter=200,\n",
    "        cv=cv_strategy,\n",
    "        scoring=\"f1\",\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbose=2,\n",
    "    )\n",
    "\n",
    "    random_search.fit(x_train, y_train)\n",
    "\n",
    "    print(f\"Beste Parameter gefunden: {random_search.best_params_}\")\n",
    "    print(f\"Bester CV f1-Score: {random_search.best_score_:.4f}\")\n",
    "\n",
    "    final_model = HistGradientBoostingClassifier(**random_search.best_params_, random_state=42, class_weight=\"balanced\")\n",
    "    final_model.fit(x_train, y_train)\n",
    "\n",
    "    return final_model\n",
    "\n",
    "\n",
    "def calculate_success_probability(model, features: pd.DataFrame) -> float:\n",
    "    \"\"\"Calculates the success probability for a given model and features.\"\"\"\n",
    "    return model.predict_proba(features)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e22ba47d-a4f8-4bc2-9023-416827f9f6f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'processed_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m processed_data[\u001b[33m\"\u001b[39m\u001b[33mamount_bins\u001b[39m\u001b[33m\"\u001b[39m] = pd.cut(\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     processed_data[\u001b[33m\"\u001b[39m\u001b[33mamount\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      3\u001b[39m     bins=[\u001b[32m0\u001b[39m, \u001b[32m200\u001b[39m, \u001b[32m400\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33minf\u001b[39m\u001b[33m\"\u001b[39m)],\n\u001b[32m      4\u001b[39m     labels=[\u001b[33m\"\u001b[39m\u001b[33mamount_under_200\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mamount_200_400\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mamount_over_400\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      5\u001b[39m     right=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m      6\u001b[39m )\n\u001b[32m      7\u001b[39m processed_data[\u001b[33m\"\u001b[39m\u001b[33mamount_bins\u001b[39m\u001b[33m\"\u001b[39m].info()\n",
      "\u001b[31mNameError\u001b[39m: name 'processed_data' is not defined"
     ]
    }
   ],
   "source": [
    "processed_data[\"amount_bins\"] = pd.cut(\n",
    "    processed_data[\"amount\"],\n",
    "    bins=[0, 200, 400, float(\"inf\")],\n",
    "    labels=[\"amount_under_200\", \"amount_200_400\", \"amount_over_400\"],\n",
    "    right=False,\n",
    ")\n",
    "processed_data[\"amount_bins\"].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3622bb41-d06d-45f6-856e-5c25e0d50748",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_excel(RAW_DATA_PATH, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93149e2f-858a-4d4f-928f-356c1776ab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data, ohc = engineer_features(data=raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "740126db-792b-46e8-91db-3a249397b742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split features and target\n",
    "y = processed_data[\"success\"]\n",
    "X = processed_data.drop(columns=[\"success\"], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b303bf2c-1ff1-4755-8171-36b154463415",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"C:\\Users\\Erik\\Miniconda3\\Lib\\threading.py\"\u001b[0m, line \u001b[35m1041\u001b[0m, in \u001b[35m_bootstrap_inner\u001b[0m\n",
      "    \u001b[31mself.run\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "    \u001b[31m~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"C:\\Users\\Erik\\Miniconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\"\u001b[0m, line \u001b[35m766\u001b[0m, in \u001b[35mrun_closure\u001b[0m\n",
      "    \u001b[31m_threading_Thread_run\u001b[0m\u001b[1;31m(self)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"C:\\Users\\Erik\\Miniconda3\\Lib\\threading.py\"\u001b[0m, line \u001b[35m992\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "    \u001b[31mself._target\u001b[0m\u001b[1;31m(*self._args, **self._kwargs)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"C:\\Users\\Erik\\Miniconda3\\Lib\\subprocess.py\"\u001b[0m, line \u001b[35m1611\u001b[0m, in \u001b[35m_readerthread\u001b[0m\n",
      "    buffer.append(\u001b[31mfh.read\u001b[0m\u001b[1;31m()\u001b[0m)\n",
      "                  \u001b[31m~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"C:\\Users\\Erik\\Miniconda3\\Lib\\encodings\\cp1252.py\"\u001b[0m, line \u001b[35m23\u001b[0m, in \u001b[35mdecode\u001b[0m\n",
      "    return \u001b[31mcodecs.charmap_decode\u001b[0m\u001b[1;31m(input,self.errors,decoding_table)\u001b[0m[0]\n",
      "           \u001b[31m~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "\u001b[1;35mUnicodeDecodeError\u001b[0m: \u001b[35m'charmap' codec can't decode byte 0x81 in position 119: character maps to <undefined>\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "Beste Parameter gefunden: {'l2_regularization': np.float64(0.7215965507512772), 'learning_rate': np.float64(0.01961892879281754), 'max_depth': 10, 'max_iter': 366, 'min_samples_leaf': 33}\n",
      "Bester CV f1-Score: 0.4238\n"
     ]
    }
   ],
   "source": [
    "# Train models\n",
    "dtm = train_decision_tree(x_train=X_train, y_train=y_train)\n",
    "hgbm = train_hgboost(x_train=X_train, y_train=y_train)\n",
    "ohgbm = tune_hyperparameters(x_train=X_train, y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2746f202-1800-46b8-b4fa-e6d59bab1b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_evaluate = {\n",
    "    \"decision_tree_model\": dtm,\n",
    "    \"hgboost_model\": hgbm,\n",
    "    \"optimized_hgboost_model\": ohgbm,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54dedd3-6425-46d5-81f1-0934fb3d4424",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models_to_evaluate.items():\n",
    "    precision, recall, accuracy, f1, roc_auc, cm = get_scores(name, model, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b61c7b0-f053-42a2-9601-042582b17358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(\n",
    "    name: str,\n",
    "    model: DecisionTreeClassifier | HistGradientBoostingClassifier,\n",
    "    y_true: pd.Series,\n",
    "    x_test: pd.DataFrame,\n",
    "):\n",
    "    y_pred = model.predict(x_test)\n",
    "    precision = precision_score(y_true=y_true, y_pred=y_pred)\n",
    "    recall = recall_score(y_true=y_true, y_pred=y_pred)\n",
    "    roc_auc = roc_auc_score(y_true=y_true, y_score=y_pred)\n",
    "    cm = confusion_matrix(y_true=y_true, y_pred=y_pred)\n",
    "\n",
    "    return precision, recall, roc_auc, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0980c145-3c23-46ca-8430-cee153a1c6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ohgbm.predict_proba(X_test)[:, 1]\n",
    "precision, recall, _ = precision_recall_curve(y_test, predictions)\n",
    "disp = PrecisionRecallDisplay(precision=precision, recall=recall)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499d2b88-92ca-4134-a626-c4acdbc7c04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "result_hgbm = permutation_importance(hgbm, X_test, y_test, n_repeats=10, random_state=42, n_jobs=-1)\n",
    "result_ohgbm = permutation_importance(ohgbm, X_test, y_test, n_repeats=10, random_state=42, n_jobs=-1)\n",
    "perm_importance_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Feature\": X_test.columns,\n",
    "        \"dtm\": dtm.feature_importances_.round(4),\n",
    "        \"hgbm\": result_hgbm.importances_mean.round(4),\n",
    "        \"ohgbm\": result_ohgbm.importances_mean.round(4),\n",
    "    }\n",
    ").set_index(\"Feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876c6d77-06a9-41f0-acc8-b76779ef2772",
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_importance_df.ohgbm.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afb4c1d-ebd5-4f76-a558-3f5a9cfc0370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business Evaluation\n",
    "print(\"\\n--- Model Evaluation ---\")\n",
    "for name, model in models_to_evaluate.items():\n",
    "    print(f\"\\nEvaluating {name}\")\n",
    "    evaluate_technical_performance(model=model, x_test=X_test, y_test=y_test)\n",
    "    evaluate_business_impact(model=model, x_test=X_test, y_test=y_test, original_data=raw_data)\n",
    "print(\"\\n--- Evaluation complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb97192-fa46-4da8-ac0d-01e6c6a0059b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(\n",
    "    x_test: pd.DataFrame,\n",
    "    y_test: pd.Series,\n",
    "    model: HistGradientBoostingClassifier | DecisionTreeClassifier,\n",
    ") -> None:\n",
    "    preds = model.predict(x_test)\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    labels = [0, 1]\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    print(cm)\n",
    "    disp.plot()\n",
    "\n",
    "\n",
    "def evaluate_technical_performance(model, x_test: pd.DataFrame, y_test: pd.DataFrame) -> None:\n",
    "    \"\"\"Evaluates the model on the test set by calculating accuracy.\"\"\"\n",
    "    y_pred_proba = calculate_success_probability(model, x_test)\n",
    "    score = roc_auc_score(y_test, y_pred_proba)\n",
    "    print(f\"ROC AUC Score: {score:.4f}\")\n",
    "\n",
    "\n",
    "def _calculate_actual_costs(choices, y_true) -> float:\n",
    "    \"\"\"\n",
    "    Helper function to calculate the total actual cost for a series of PSP choices\n",
    "    based on the true transaction outcomes.\n",
    "    \"\"\"\n",
    "    total_cost = 0\n",
    "\n",
    "    for index, psp_choice in choices.items():\n",
    "        if psp_choice in PSP_COSTS:\n",
    "            cost_dict = PSP_COSTS[psp_choice]\n",
    "            # Use the true outcome (y_true) to determine the actual cost\n",
    "            actual_cost = cost_dict[\"success\"] if y_true.loc[index] else cost_dict[\"failure\"]\n",
    "            total_cost += actual_cost\n",
    "    return total_cost\n",
    "\n",
    "\n",
    "def evaluate_business_impact(model, x_test: pd.DataFrame, y_test: pd.DataFrame, original_data: pd.DataFrame) -> None:\n",
    "    \"\"\"Evaluates and compares the financial outcome of the model's routing strategy\n",
    "    against the legacy system's strategy on the test set.\"\"\"\n",
    "    all_model_columns = x_test.columns.tolist()\n",
    "    expected_costs_df = pd.DataFrame(index=x_test.index)\n",
    "\n",
    "    for psp in PSP_COSTS:\n",
    "        simulated_features = x_test.copy()\n",
    "\n",
    "        for col in all_model_columns:\n",
    "            if col.startswith(\"PSP_\"):\n",
    "                simulated_features[col] = 0\n",
    "        simulated_features[f\"PSP_{psp}\"] = 1\n",
    "        simulated_features = simulated_features.reindex(columns=all_model_columns, fill_value=0)\n",
    "        prob_success = calculate_success_probability(model, simulated_features)\n",
    "\n",
    "        expected_costs_df[psp] = (\n",
    "            prob_success * PSP_COSTS[psp][\"success\"] + (1 - prob_success) * PSP_COSTS[psp][\"failure\"]\n",
    "        )\n",
    "\n",
    "    # Calculate Model Strategy Cost\n",
    "    model_choices = expected_costs_df.idxmin(axis=1)\n",
    "    total_cost_model = _calculate_actual_costs(model_choices, y_test)\n",
    "\n",
    "    # Calculate Legacy System Cost\n",
    "    legacy_choices = original_data.loc[x_test.index, \"PSP\"]\n",
    "    total_cost_legacy = _calculate_actual_costs(legacy_choices, y_test)\n",
    "\n",
    "    # Report the Financial Outcome\n",
    "    savings = total_cost_legacy - total_cost_model\n",
    "    savings_percent = (savings / total_cost_legacy) * 100 if total_cost_legacy > 0 else 0\n",
    "\n",
    "    print(f\"  Legacy System Cost: {total_cost_legacy:,.2f} â¬\")\n",
    "    print(f\"  Model Strategy Cost: {total_cost_model:,.2f} â¬\")\n",
    "    print(f\"  Savings: {savings:,.2f} â¬ ({savings_percent:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119b95e5-d33b-4b3e-bb6a-4ecffb43c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = processed_data[\"is_retry\"] & processed_data[\"success\"]\n",
    "tmp.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48159465-078c-40b2-877b-40b260f799bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data[\"is_retry\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0aab4b-6030-4144-bb56-5acab808528b",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data.groupby(\"is_retry\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdcb500-93e1-4951-8aea-ae277107c6a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
